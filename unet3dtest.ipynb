{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab3ee3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 240, 160)\n",
      "[-0.40676096 -0.40419534 -0.40162972 ...  3.405744    3.4083095\n",
      "  3.410875  ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'slicez = image[150, :, :]\\nslicey = image[:, 150, :]\\nslicex = image[:, :, 100]\\n\\nslices = [slicez, slicey, slicex]\\n\\nfig, axes = plt.subplots(1, 3, figsize=(14, 21))\\nfor i, s in enumerate(slices):\\n    axes[i].imshow(np.flipud(s.T), cmap=\\'gray\\')\\n    axes[i].axis(\"off\")'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "image = nib.load('/Users/daniel/Documents/CSAI/Advanced Deep Learning/CODE/data/train/BraTS2021_00000/BraTS2021_00000_flair.nii.gz')\n",
    "mask = nib.load('/Users/daniel/Documents/CSAI/Advanced Deep Learning/CODE/data/train/BraTS2021_00000/BraTS2021_00000_seg.nii.gz')\n",
    "\n",
    "image = np.asanyarray(image.dataobj, dtype=np.float32)\n",
    "mask = np.asanyarray(mask.dataobj, dtype=np.float32)\n",
    "\n",
    "image = np.pad(image, ((0, 0), (0, 0), (2, 3)), mode='constant', constant_values=0)\n",
    "mask = np.pad(mask, ((0, 0), (0, 0), (2, 3)), mode='constant', constant_values=0)\n",
    "\n",
    "print(image.shape)\n",
    "\n",
    "image = (image - image.mean()) / image.std()\n",
    "\n",
    "p1 = np.percentile(image, 1)\n",
    "p99 = np.percentile(image, 99)\n",
    "image = np.clip(image, p1, p99)\n",
    "\n",
    "unique_vals = np.unique(image)\n",
    "print(unique_vals)\n",
    "\n",
    "'''slicez = image[150, :, :]\n",
    "slicey = image[:, 150, :]\n",
    "slicex = image[:, :, 100]\n",
    "\n",
    "slices = [slicez, slicey, slicex]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 21))\n",
    "for i, s in enumerate(slices):\n",
    "    axes[i].imshow(np.flipud(s.T), cmap='gray')\n",
    "    axes[i].axis(\"off\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebfbf06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: torch.Size([1, 1, 240, 240, 160])\n",
      "Mask batch shape: torch.Size([1, 1, 240, 240, 160])\n"
     ]
    }
   ],
   "source": [
    "import bratsdataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#constructing datasets\n",
    "train_path = '/Users/daniel/Documents/CSAI/Advanced Deep Learning/CODE/data/train/'\n",
    "train_set = bratsdataset.BratsDataset(train_path)\n",
    "\n",
    "val_path = '/Users/daniel/Documents/CSAI/Advanced Deep Learning/CODE/data/validation/'\n",
    "val_set = bratsdataset.BratsDataset(train_path)\n",
    "\n",
    "test_path = '/Users/daniel/Documents/CSAI/Advanced Deep Learning/CODE/data/test/'\n",
    "test_set = bratsdataset.BratsDataset(train_path)\n",
    "\n",
    "#data loaders\n",
    "batch_size = 1 #8\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#test\n",
    "images, masks = next(iter(train_loader))\n",
    "print(\"Image batch shape:\", images.shape)\n",
    "print(\"Mask batch shape:\", masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eaade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "import models\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model = models.Unet3Dbrats()\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 1 #1000\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "early_stopping = utils.EarlyStopping(patience=10, delta=0.1)\n",
    "\n",
    "#training loop\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    #training\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for images, masks in train_loader:\n",
    "\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #balance the loss per batch size\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    train_loss_list.append(train_loss)\n",
    "\n",
    "    #validation\n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for images, masks in val_loader:\n",
    "\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            #balance the loss per batch size\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "        \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    val_loss_list.append(val_loss)\n",
    "\n",
    "\n",
    "    early_stopping.check(val_loss)\n",
    "    if early_stopping.stop_training:\n",
    "        break\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]  Train Loss: {train_loss:.4f}  Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Runtime {end - start}\")\n",
    "\n",
    "#plot training and validation loss\n",
    "plt.figure()\n",
    "plt.plot(train_loss_list, label='training loss')\n",
    "plt.plot(val_loss_list,label='validation loss')\n",
    "plt.legend()\n",
    "plt.show\n",
    "plt.savefig(\"Images/loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d39203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing loop\n",
    "test_dice = 0.0\n",
    "test_loss = 0.0\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for images, masks in test_loader:\n",
    "\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        dice = utils.dice_coeff(outputs, masks)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        #balance the loss per batch size\n",
    "        test_dice += dice * images.size(0)\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "    \n",
    "test_dice /= len(test_loader.dataset)    \n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "print(f\"Mean dice coefficient on test set: {test_dice:.4f}\")\n",
    "print(f\"Mean loss on test set: {test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
